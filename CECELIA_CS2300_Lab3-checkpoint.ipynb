{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b906a9",
   "metadata": {},
   "source": [
    "# CS 2300 Lab 3: Search Terms w Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf9592",
   "metadata": {},
   "source": [
    "Cecelia Henson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912ac7b",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The purpose of this lab is to build on my **Lab 2: Search Terms** where I analyzed search terms using lists, sets, and dictionaries in Python for basic data cleaning and natural language processing tasks. The search terms were provided by Direct Supply's DSS eProcedure system containing queries entere by food-service users over a 60 day period from 2019\n",
    "\n",
    "However in this lab I am using pandas to store the full list of tokens instead of the built in Python data structures combined with functional programming to improve the performance and get the same results as I did in the **Lab 2** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf68d61",
   "metadata": {},
   "source": [
    "**Importing necessary libaries and creating list and dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1d6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from spellchecker import SpellChecker\n",
    "import pandas as pd\n",
    "import sys\n",
    "freq_dict = {}\n",
    "freq_dict_spellchecked = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180be639",
   "metadata": {},
   "source": [
    "#### Upload List:\n",
    "The **import_csv_list** function imports a CSV file and creates a dataframe of the first item in each row, removed the webspaces and splits search terms by space\n",
    "\n",
    "Note: I had to limit the amount to the data set for it to run in a decent amount of time for the list version, the dataframe didn't have any runtime duration issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e9a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_list(csv):\n",
    "    temp = []\n",
    "    csv_raw_data = []\n",
    "    i = 0\n",
    "    with open(csv ,encoding = \"utf8\") as file:\n",
    "        for line in file:\n",
    "            if i == 200000:\n",
    "                break\n",
    "            temp.append(line.rstrip('\\n').split(','))\n",
    "            i+=1\n",
    "    file.close\n",
    "    remove_web_spaces = [str(row[0]).replace(\"%20\", \" \") for row in temp]\n",
    "    split_on_space_list = []\n",
    "    for item in remove_web_spaces:\n",
    "        split_on_space_list.extend(item.split(\" \"))\n",
    "    df = pd.DataFrame({\"Raw Data\" : split_on_space_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5e119",
   "metadata": {},
   "source": [
    " #### List Frequency:\n",
    " Creates a frequency dictionary given a string lust where the key is a string and the key-value is how many times the string appreared in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f12a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_freq_dict(input_list):\n",
    "    freq_dict = {}\n",
    "    for i in input_list:\n",
    "        freq_dict[i] = input_list.count(i)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f380fa",
   "metadata": {},
   "source": [
    "#### Sort Frequency:\n",
    "Creates a sorted frequency list given a frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf11e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq_dict):\n",
    "    sorted_list = [(freq_dict[key], key) for key in freq_dict]\n",
    "    sorted_list.sort()\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b8daf",
   "metadata": {},
   "source": [
    "#### SpellChecker\n",
    "Creates a spellchecker dictionary where the key is misspelled word and the key-value is the most likely corrected word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857d249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_dict_init(input_list):\n",
    "    spell = SpellChecker(distance=1)\n",
    "    spellchecked_dict = {}\n",
    "    for word in input_list:\n",
    "        spellchecked_dict[word] = spell.correction(word)\n",
    "    return spellchecked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49652048",
   "metadata": {},
   "source": [
    "#### Spell check token\n",
    "Given a misspelled string token, returns the most likely corrected word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74b3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_token(token):\n",
    "    fixed_token = ''\n",
    "    if(token != ''):\n",
    "        fixed_token = spellcheck_dict[token]\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1eb0d1",
   "metadata": {},
   "source": [
    "### Testing \n",
    "This cell imports the csv to the search term data frame and filters the data from the dataset by removing non-alphabet charcters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d8c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 206 ms\n",
      "Wall time: 175 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "df = import_csv_list(\"searchTerms.csv\")\n",
    "\n",
    "%time df[\"Removed Numbers\"] = df[\"Raw Data\"].str.replace('[0-9]', '')\n",
    "%time df[\"Letters Only\"] = df[\"Removed Numbers\"].str.replace('[^a-zA-Z]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d83ee7",
   "metadata": {},
   "source": [
    "This is the cell spellchecks the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0505b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>Removed Numbers</th>\n",
       "      <th>Letters Only</th>\n",
       "      <th>Spellchecked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SearchTerm</td>\n",
       "      <td>SearchTerm</td>\n",
       "      <td>SearchTerm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36969</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500100</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KEND</td>\n",
       "      <td>KEND</td>\n",
       "      <td>KEND</td>\n",
       "      <td>kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5750</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>980228</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DYNC1815H</td>\n",
       "      <td>DYNCH</td>\n",
       "      <td>DYNCH</td>\n",
       "      <td>lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DYND70642</td>\n",
       "      <td>DYND</td>\n",
       "      <td>DYND</td>\n",
       "      <td>dyed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Raw Data Removed Numbers Letters Only Spellchecked\n",
       "0  SearchTerm      SearchTerm   SearchTerm         None\n",
       "1       36969                                          \n",
       "2        CMED            CMED         CMED          med\n",
       "3      500100                                          \n",
       "4        KEND            KEND         KEND         kind\n",
       "5        5750                                          \n",
       "6        CMED            CMED         CMED          med\n",
       "7      980228                                          \n",
       "8   DYNC1815H           DYNCH        DYNCH        lynch\n",
       "9   DYND70642            DYND         DYND         dyed"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "spellcheck_dict = spellcheck_dict_init(df[\"Letters Only\"].tolist())\n",
    "\n",
    "df[\"Spellchecked\"] = df[\"Letters Only\"].map(lambda token: spellcheck_token(token))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f236f9",
   "metadata": {},
   "source": [
    "This cell benchmarks the time it takes for the data frame approach for the sorted frequency list of search terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37de27e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           42701\n",
       "chicken     3640\n",
       "bacon       2698\n",
       "juice       2627\n",
       "beef        2581\n",
       "cream       2575\n",
       "cheese      2443\n",
       "pork        2193\n",
       "green       2143\n",
       "diced       2017\n",
       "Name: Spellchecked, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time series_freq = df[\"Spellchecked\"].value_counts(dropna = True)\n",
    "series_freq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb2f29",
   "metadata": {},
   "source": [
    "This cell benchmarks the time it takes for the dictionary and list sorted frequency list of search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e264e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spellcheck_freq_dict = list_to_freq_dict(df[\"Spellchecked\"].tolist())\n",
    "spellcheck_freq_list = sort_freq_dict(spellcheck_freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2ccf7",
   "metadata": {},
   "source": [
    "This cell benchmarks the size of the sorted frequency data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d42bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371725"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_freq.memory_usage(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4be5e",
   "metadata": {},
   "source": [
    "This cell benchmarks the size of the sorted frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cea628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47160"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(spellcheck_freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d116d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332347b7",
   "metadata": {},
   "source": [
    "The time to removed all non alphabet characters form the dataset took 369 ms at first to remove the numbers and then 255 ms to remove all uppercase letters as well. This benchmark difference was because the second dataset filter had a smaller amount of opertations to do compared to the original, because of this it allows for a faster runtime. \n",
    "\n",
    "The runtime for the spellchecked dataset took 25.9 ms while the list version took 19 min and 1 secong which is significantly longer than the dataset benchmark because the **value_counts** function that is in the Pandas library uses a single loop through the data while the list has more steps to do the same process. Because of the functional programming it has to go through the list_to_freq_dict method, get that result and then go back through the sort_freq_dict method to sort and reverse which leads to a longer runtime for the way that I programmed this lab as the values get bigger and bigger, which is why I could only use 200,000 entries for this because if I used any more it would take too long for the list version\n",
    "\n",
    "Pandas overall through this lab compared to the previous one has shown that it can be useful in the sense of minimizing the amount of code that has to be written for data minipulation while giving a faster runtime at the same time as a developer. However, it comes with the disadvantage of the significant amount of memory that is used because of it because even though the list version of the spellchecked data took 19 minutes, the amount of memeory used was only 47160, while the dataset took 25 ms but the memory usage was huge at 371725 and memory can get very expensive. It also can be difficult to decipher at time with the amount of dataframes being created since there are no function headers describing what it contains, you would have to go through from top to bottom if given a random persons project with a bunch of dataframes or go back to a personal project that you haven't worked on in a while. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling and Timing Code\n",
    "#### Cecelia Henson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of developing code and creating data processing pipelines, there are often trade-offs you can make between various implementations.\n",
    "Early in developing your algorithm, it can be counterproductive to worry about such things. As Donald Knuth famously quipped, \"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"\n",
    "\n",
    "Once you have your code working, it can be useful to dig into its efficiency a bit.\n",
    "Sometimes it's useful to check the execution time of a given command or set of commands; other times it's useful to dig into a multiline process and determine where the bottleneck lies in some complicated series of operations.\n",
    "IPython provides access to a wide array of functionality for this kind of timing and profiling of code.\n",
    "Here we'll discuss the following IPython magic commands:\n",
    "\n",
    "- ``%time``: Time the execution of a single statement\n",
    "- ``%timeit``: Time repeated execution of a single statement for more accuracy\n",
    "- ``%prun``: Run code with the profiler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Code Snippets: ``%timeit`` and ``%time``\n",
    "\n",
    "``%timeit`` line-magic and ``%%timeit`` cell-magic can be used to time the repeated execution of snippets of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 µs ± 66 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because this operation is so fast, ``%timeit`` automatically does a large number of repetitions.\n",
    "For slower commands, ``%timeit`` will automatically adjust and perform fewer repetitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 ms ± 9.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes repeating an operation is not the best option.\n",
    "For example, if we have a list that we'd like to sort, we might be misled by a repeated operation.\n",
    "Sorting a pre-sorted list is much faster than sorting an unsorted list, so the repetition will skew the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 ms ± 65 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, the ``%time`` magic function may be a better choice. It also is a good choice for longer-running commands, when short, system-related delays are unlikely to affect the result.\n",
    "Let's time the sorting of an unsorted and a presorted list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an unsorted list:\n",
      "Wall time: 19.2 ms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "print(\"sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an already sorted list:\n",
      "Wall time: 2.96 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"sorting an already sorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much faster the presorted list is to sort, but notice also how much longer the timing takes with ``%time`` versus ``%timeit``, even for the presorted list!\n",
    "This is a result of the fact that ``%timeit`` does some clever things under the hood to prevent system calls from interfering with the timing.\n",
    "For example, it prevents cleanup of unused Python objects (known as *garbage collection*) which might otherwise affect the timing.\n",
    "For this reason, ``%timeit`` results are usually noticeably faster than ``%time`` results.\n",
    "\n",
    "For ``%time`` as with ``%timeit``, using the double-percent-sign cell magic syntax allows timing of multiline scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 438 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on ``%time`` and ``%timeit``, as well as their available options, use the IPython help functionality (i.e., type ``%time?`` at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Full Scripts: ``%prun``\n",
    "\n",
    "A program is made of many single statements, and sometimes timing these statements in context is more important than timing them on their own.\n",
    "Python contains a built-in code profiler (which you can read about in the Python documentation), but IPython offers a much more convenient way to use this profiler, in the form of the magic function ``%prun``.\n",
    "\n",
    "By way of example, we'll define a simple function that does some calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call ``%prun`` with a function call to see the profiled results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, the output is printed to the pager, and looks something like this:\n",
    "\n",
    "```\n",
    "14 function calls in 0.714 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        5    0.599    0.120    0.599    0.120 <ipython-input-19>:4(<listcomp>)\n",
    "        5    0.064    0.013    0.064    0.013 {built-in method sum}\n",
    "        1    0.036    0.036    0.699    0.699 <ipython-input-19>:1(sum_of_lists)\n",
    "        1    0.014    0.014    0.714    0.714 <string>:1(<module>)\n",
    "        1    0.000    0.000    0.714    0.714 {built-in method exec}\n",
    "```\n",
    "\n",
    "The result is a table that indicates, in order of total time on each function call, where the execution is spending the most time. In this case, the bulk of execution time is in the list comprehension inside ``sum_of_lists``.\n",
    "From here, we could start thinking about what changes we might make to improve the performance in the algorithm.\n",
    "\n",
    "For more information on ``%prun``, as well as its available options, use the IPython help functionality (i.e., type ``%prun?`` at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Profiling\n",
    "In many cases it is useful to know how much storage space something requires.  Python's system library (sys) provides a getsizeof() method that returns the number of bytes used by the variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "54\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "my_int = 1\n",
    "my_string = \"hello\"\n",
    "my_double = 3.14159\n",
    "\n",
    "print(sys.getsizeof(my_int))\n",
    "print(sys.getsizeof(my_string))\n",
    "print(sys.getsizeof(my_double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, add at least 4 more new objects and primitives to test their sizes.  See if you can find the primitive that takes the least space.  Do big numbers require more storage?  How is python different than Java when it comes to primitive storage sizes?\n",
    "\n",
    "Answer: The primative that takes the most space are the double and floatng points. Bigger numbers do not require more storage because having an int be 1 or being 70,000 it still resulted in the same amount of storage space that it requires. Python is different than Java when it comes to primative storage sizes because Jave stores primatives using 32 bit memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "84\n",
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "test_value_1 = 70000\n",
    "test_value_2 = \"This is a longer string than before\"\n",
    "test_value_4 = 70.238291183920\n",
    "test_value_5 = 0.24313618\n",
    "\n",
    "print(sys.getsizeof(test_value_1))\n",
    "print(sys.getsizeof(test_value_2))\n",
    "print(sys.getsizeof(test_value_4))\n",
    "print(sys.getsizeof(test_value_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we explore what size differences exist between various lists and other data structures.  Add a data structure for a dict as well to see what size it is.  Why are some of these are equal to each other?  Reading the documentation might be helpful: https://docs.python.org/3/library/sys.html\n",
    "\n",
    "Answer: The test.clear() and test.reverse() were the same size because with sys.getsizeof() it only accounts for the memory consumption that is directly affecting the object not what it refers to, this means that the size of the action on the data structrue is seen as the same when affecting test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "64\n",
      "64\n",
      "152\n",
      "152\n",
      "\n",
      "\n",
      "232\n",
      "216\n",
      "120\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(sys.getsizeof([]))\n",
    "print(sys.getsizeof([1]))\n",
    "print(sys.getsizeof(['a quick brown fox jumped over the lazy dog']))\n",
    "print(sys.getsizeof([1,2,3,4,5,6,7,8,9]))\n",
    "print(sys.getsizeof([\"a\",\"quick\",\"brown\",\"fox\",\"jumped\",\"over\",\"the\",\"lazy\",\"dog\"]))\n",
    "print('\\n')\n",
    "test = ['a', 'b', 'c', 'd']\n",
    "test_set = {1, 2, 3, 4}\n",
    "\n",
    "print(sys.getsizeof(dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])))\n",
    "\n",
    "print(sys.getsizeof(test_set))\n",
    "print(sys.getsizeof(test))\n",
    "\n",
    "print(sys.getsizeof(test.clear()))\n",
    "print(sys.getsizeof(test.reverse()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't figured it out yet, the memory that is reported only accounts for the space to store the reference to the object, not to the underlying objects contained therein.  Therefore, we need a recursive way to find the actual memory footprint of the object.  Consider the following method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof,stderr\n",
    "from itertools import chain\n",
    "from collections import deque\n",
    "try:\n",
    "    from reprlib import repr\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def total_size(o, handlers={}, verbose=False):\n",
    "    \"\"\" Returns the approximate memory footprint an object and all of its contents.\n",
    "\n",
    "    Automatically finds the contents of the following builtin containers and\n",
    "    their subclasses:  tuple, list, deque, dict, set and frozenset.\n",
    "    To search other containers, add handlers to iterate over their contents:\n",
    "\n",
    "        handlers = {SomeContainerClass: iter,\n",
    "                    OtherContainerClass: OtherContainerClass.get_elements}\n",
    "                    \n",
    "    Source: https://code.activestate.com/recipes/577504/\n",
    "    \"\"\"\n",
    "    dict_handler = lambda d: chain.from_iterable(d.items())\n",
    "    all_handlers = {tuple: iter,\n",
    "                    list: iter,\n",
    "                    deque: iter,\n",
    "                    dict: dict_handler,\n",
    "                    set: iter,\n",
    "                    frozenset: iter,\n",
    "                   }\n",
    "    all_handlers.update(handlers)     # user handlers take precedence\n",
    "    seen = set()                      # track which object id's have already been seen\n",
    "    default_size = getsizeof(0)       # estimate sizeof object without __sizeof__\n",
    "\n",
    "    def sizeof(o):\n",
    "        if id(o) in seen:       # do not double count the same object\n",
    "            return 0\n",
    "        seen.add(id(o))\n",
    "        s = getsizeof(o, default_size)\n",
    "\n",
    "        if verbose:\n",
    "            print(s, type(o), repr(o), file=stderr)\n",
    "\n",
    "        for typ, handler in all_handlers.items():\n",
    "            if isinstance(o, typ):\n",
    "                s += sum(map(sizeof, handler(o)))\n",
    "                break\n",
    "        return s\n",
    "\n",
    "    return sizeof(o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, use the method above to calculate the actual size of the objects you created above.  Please record any reactions to this exercise in the last cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "56\n",
      "328\n",
      "476\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(total_size(test_value_4))\n",
    "print(total_size(test))\n",
    "print(total_size(test_set))\n",
    "print(total_size(dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])))\n",
    "print(total_size([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put reactions to this assignment here\n",
    "\n",
    "When I calculated the total_size function with primative objects the value did not change but when I used python data structures like list and sets I got a different number for the total size of the object. My list value when using sys.getsizeof() was 120 but when I used the total_size method I got 56 as the actual size of my list object. When I did my set value when using sys.getsizeof() I got a result of 216 but with the total_size method it ended uo being larger and having a true total size of 328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "This content has been modified by Dr. Derek Riley"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

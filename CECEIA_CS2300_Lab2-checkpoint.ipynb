{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b56d783",
   "metadata": {},
   "source": [
    "# CS 2300 Lab 2: Search Terms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5af6c1",
   "metadata": {},
   "source": [
    "By: Cecelia Henson "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57560e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The purpose of this lab is to analyze search terms using lists, sets, and dictionaries in Python for basic data cleaning and natural language processing tasks. Search terms provided by Direct Supply's DSS eProcedure system containing queries entere by food-service users over a 60 day period from 2019\n",
    "\n",
    "The csv file will filter search queries and create single tokens with no spaces and a frequency dictrionary from that list and is then searched from most searched to least searched terms. Then a second dictionary is created with frequency of the original filtered list but that has been spellchecked with the spellchecker library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49440fe",
   "metadata": {},
   "source": [
    "#### Importing SpellChecker and csv and creating list and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a86c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "csv_freq_dict = {}\n",
    "csv_freq_spellchecked = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677de60",
   "metadata": {},
   "source": [
    "## Upload List:\n",
    "\n",
    "The **import_csv_list** function imports a CSV file and creates a list of the first item in each row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_list(csv):\n",
    "    temp = []\n",
    "    csv_raw_data = []\n",
    "    i = 0\n",
    "    with open(csv ,encoding = \"utf8\") as file:\n",
    "        for line in file:\n",
    "            if i == 70000:\n",
    "                break\n",
    "            temp.append(line.rstrip('\\n').split(','))\n",
    "            i+=1\n",
    "    csv_raw_data = [str(row[0]) for row in temp]\n",
    "    file.close\n",
    "    return csv_raw_data\n",
    "\n",
    "#import_csv_list('searchTerms.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089054e9",
   "metadata": {},
   "source": [
    "## Split Tokens:\n",
    "\n",
    "The **split_tokens** function takes a list of string and creates a new list where each string is split by spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778f323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(original_list):\n",
    "    new_list = []\n",
    "    for item in original_list:\n",
    "        new_list.extend(item.split(\" \"))\n",
    "    return new_list\n",
    "\n",
    "#split_tokens(import_csv_list('searchTerms.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38ffcf",
   "metadata": {},
   "source": [
    "## Web Spaces: \n",
    "\n",
    "The **remove_web_spaces** function relaces the web spaces (%20) with a regular space from a string token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325f041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_web_spaces(token):\n",
    "    token.replace(\"%20\", \" \")\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78220e56",
   "metadata": {},
   "source": [
    "## Non-Alphabet:\n",
    "\n",
    "The remove **non_alphabet** function removed any non-alphabet characters from the string token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18701998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabet(token):\n",
    "    fixed_token = \"\"\n",
    "    for char in token:\n",
    "        if(char.isalpha() or char == \" \"):\n",
    "            fixed_token = fixed_token + char\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499eafc3",
   "metadata": {},
   "source": [
    "## List Frequency:\n",
    "\n",
    "The **list_to_freq_dict** function creates a frequency dictionary given a list of strings where the key is a string and the key-value is how many time the string apprears in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdadb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_freq_dict(input_list):\n",
    "    freq_dict = {}\n",
    "    for i in input_list:\n",
    "        freq_dict[i] = input_list.count(i)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484fdc3",
   "metadata": {},
   "source": [
    "## Sort Frequency:\n",
    "\n",
    "The **sort_freq_dict** function creates a sorted frequency list given a frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9309f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq_dict):\n",
    "    sorted_list = [(freq_dict[key], key) for key in freq_dict]\n",
    "    sorted_list.sort()\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7dc05d",
   "metadata": {},
   "source": [
    "## SpellChecker: \n",
    "\n",
    "The **spellcheck_dict_init** function creates a spellchecker dictionary where the key is the misspelled word and they key-value is the most likely correct spelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d431c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_dict_init(input_list):\n",
    "    spell = SpellChecker(distance=1)\n",
    "    spellchecked_dict = {}\n",
    "    for word in input_list:\n",
    "        spellchecked_dict[word] = spell.correction(word)\n",
    "    return spellchecked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a1584",
   "metadata": {},
   "source": [
    "## SpellCheck Token: \n",
    "\n",
    "The **spellcheck_token** function returns the most likely corrected word given a misspelled string token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c01388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_token(token):\n",
    "    fixed_token = csv_spellcheck_dict[token]\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845bdc8",
   "metadata": {},
   "source": [
    "## Create CSV:\n",
    "\n",
    "The **list_to_csv** function creates a csv files from a frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48082a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_csv(input_list):\n",
    "    fields = [\"Frequency\", \"Word\"]\n",
    "    with open(\"frequencyOfSearchTerms.csv\", \"w\", newline = \"\") as file:\n",
    "        write = csv.writer(file)\n",
    "        write.writerow(fields)\n",
    "        write.writerows(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee41fd",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71e817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "# Importing csv to searchterms list\n",
    "%time csv_raw = import_csv_list(\"searchTerms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9e014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This filters the data from the csv file by removing non \n",
    "# alphabet character and replacing web spaces with spaces, \n",
    "# while splitting search terms by word\n",
    "csv_filtered = []\n",
    "for i in range(len(csv_raw)):\n",
    "    temp = remove_non_alphabet(remove_web_spaces(csv_raw[i]))\n",
    "    csv_filtered.append(temp)\n",
    "    \n",
    "#print(csv_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e08a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.4 ms\n"
     ]
    }
   ],
   "source": [
    "# This splits the filtered list into tokens\n",
    "%time csv_filtered = split_tokens(csv_filtered)\n",
    "\n",
    "#print(csv_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1f2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This section removes all the blank serch terms\n",
    "# that are generated by the removal of non-alphabet \n",
    "# characters\n",
    "csv_fixed = []\n",
    "for word in csv_filtered:\n",
    "    if len(word) != 0:\n",
    "        csv_fixed.append(word)\n",
    "        \n",
    "#print(csv_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79c46119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 57s\n",
      "Wall time: 15.1 ms\n"
     ]
    }
   ],
   "source": [
    "# This createsa frequency dictionary of the filterd data\n",
    "# A list is also creatd to sort the frequency dictionary\n",
    "# from most frequent to least frequent\n",
    "%time csv_freq_dict = list_to_freq_dict(csv_fixed)\n",
    "%time csv_freq_list = sort_freq_dict(csv_freq_dict)\n",
    "\n",
    "\n",
    "#print(csv_freq_dict)\n",
    "#print(csv_freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae85a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This creates a spellchecked version of the fully filteres \n",
    "# version and creates a frequency dictionary and sorted\n",
    "# list of the most frequent \n",
    "csv_spellcheck_dict = spellcheck_dict_init(csv_fixed)\n",
    "csv_spellchecked = []\n",
    "for word in csv_fixed:\n",
    "    csv_spellchecked.append(spellcheck_token(word))\n",
    "##print(csv_spellchecked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73166e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 35s\n",
      "Wall time: 2.04 ms\n"
     ]
    }
   ],
   "source": [
    "%time csv_spellchecked_dict = list_to_freq_dict(csv_spellchecked)\n",
    "%time csv_spellchecked_freq = sort_freq_dict(csv_spellchecked_dict)\n",
    "#print(csv_spellchecked_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fdeacfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Creates a csv file of spellchecked search terms \n",
    "# frequency list from most frequent to least\n",
    "# frequent\n",
    "%time list_to_csv(csv_spellchecked_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e889a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**1:** The most frequent search token for both the non-spellchecked data and spell-checked data was bacon which had 459 search queries, followed by 180 queries of milk, 168 queries of chicken and 140 queries of beef. I believe that this could be a result of the \"typical\" American breakfast that people have in their household and nursing homes. Humans require food to function and having a nutritious breakfast is important for health and wellness which shows in the high queries for items that are in the American breakfast\n",
    "\n",
    "**2:** My hypothesis for the \"nonwords\" within the original list of search terms csv is that they could be a lookup code associated to a specific product that certain companies or nursing homes order frequently. That could relate to allergy reqirements or food restrictions and by having the \"nonwords\" makes the organization or lookup a lot easier to confirm it is correct.\n",
    "\n",
    "**3:** I think that they spellchecked data is more accurate than the non-spellchecked version of the data but only by a small amount. The accuracy is due to how to how it fixed the misspelling containing small errors and the spellchecker has a decent accuracy in its spelling prediction. The only aspect that the spellchecking could be an issue is that spelling properties like spelling potato as potatoe. The spellchecking could see that as accidentally misspelling the plural form and add a \"s\" instead of correcting it to potato and removing the \"e\"\n",
    "\n",
    "**4:** The longest running cell is **list_to_freq_dict** because of the count method that had to iterate through each item in the list. The Big-O would be O(n^2) operation due to having to iterate through the each element in the list. When running the non-spellchecked the wall time was 3.23s and spellchecked the wall time was 3.41s.\n",
    "\n",
    "**5:** I predict that if the  list is 10x bigger it would take 100x longer and at 100x bigger it would take 10000x longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94171b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
